{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b768ea-1653-45a4-bab1-1f26477da9ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'timm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflwr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstrategy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FedAvg\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshapley_values\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtimm\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'timm'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import time\n",
    "from typing import Callable, Dict, List, Optional, OrderedDict, Tuple, Union\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import yaml\n",
    "from datasets import Dataset\n",
    "from flwr_datasets import FederatedDataset\n",
    "from flwr_datasets.partitioner import (\n",
    "    DirichletPartitioner,\n",
    "    LinearPartitioner,\n",
    "    SizePartitioner,\n",
    "    SquarePartitioner,\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "from flwr.common.typing import NDArrays\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "from flwr.client import Client\n",
    "from flwr.common import (\n",
    "    Code,\n",
    "    Context,\n",
    "    EvaluateIns,\n",
    "    EvaluateRes,\n",
    "    FitIns,\n",
    "    FitRes,\n",
    "    NDArrays, \n",
    "    Status,\n",
    "    ndarrays_to_parameters,\n",
    "    Parameters, \n",
    "    parameters_to_ndarrays,\n",
    "    Scalar,\n",
    ")\n",
    "import random\n",
    "\n",
    "import flwr as fl\n",
    "import pandas as pd\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from pyarrow import feather\n",
    "\n",
    "from flwr.server.strategy import FedAvg\n",
    "import shapley_values\n",
    "#import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b30c26-1e72-43d4-838f-22b362f02a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For faster computation, we load datasets to the GPU as a dedicated CUDA_VisionDataSet\n",
    "\n",
    "class TrainingCalls:\n",
    "    get_model: Callable = None\n",
    "    train: Callable = None\n",
    "    test: Callable = None\n",
    "    get_parameters: Callable = None\n",
    "    set_parameters: Callable = None\n",
    "    load_data: Callable = None\n",
    "    load_global_test_data: Callable = None\n",
    "    get_initial_parameters: Callable = None\n",
    "\n",
    "\n",
    "class GlobalArgs:\n",
    "    save_name: str = str(time.time())\n",
    "    num_clients: int = 2\n",
    "    epochs: int = 5\n",
    "    seed: int = 0\n",
    "    alpha: float = 1.0\n",
    "    model_name: str = \"mobilenetv3_small_050\"\n",
    "    dsname: str = \"mnsit\"\n",
    "    sampler: shapley_values.Sampler = shapley_values.FullSampler\n",
    "\n",
    "    max_rounds: int = 5\n",
    "    k: int = 5\n",
    "\n",
    "\n",
    "\n",
    "def ndarrays_from_model(model: torch.nn.ModuleList) -> List[np.ndarray]:\n",
    "    \"\"\"Get model weights as a list of NumPy ndarrays.\"\"\"\n",
    "    return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "\n",
    "def ndarrays_to_model(model: torch.nn.ModuleList, params: List[np.ndarray]):\n",
    "    \"\"\"Set model weights from a list of NumPy ndarrays.\"\"\"\n",
    "    params_dict = zip(model.state_dict().keys(), params)\n",
    "    state_dict = OrderedDict({k: torch.from_numpy(np.copy(v)) for k, v in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e723d06-01db-420c-af13-d6dd8910c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_args: GlobalArgs = GlobalArgs()\n",
    "global_args.seed = 1\n",
    "#global_args.save_name = f\"cifar100_{SEED}_{time.time()}\"\n",
    "global_args.num_clients = 5\n",
    "global_args.max_rounds = 2\n",
    "global_args.fraction_fit = 1\n",
    "global_args.alpha = 100\n",
    "global_args.sampler = shapley_values.LeaveOneOutSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e458f-b5ee-4105-a386-3f3f413d04db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model (Called when initializing FlowerClient and when testing)\n",
    "def get_model(model_name: str = 'resnet18') -> torch.nn.Module:\n",
    "    return torch.hub.load(\n",
    "        \"pytorch/vision:v0.10.0\", \"densenet121\", weights=None, verbose=False\n",
    "    ).cuda()\n",
    "    #return timm.create_model(model_name).cuda()\n",
    "\n",
    "transform_train = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        #torchvision.transforms.Resize((224,224)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        #torchvision.transforms.Resize((224,224)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def split_data(dsname, num_clients, alpha):\n",
    "    partitioner = DirichletPartitioner(\n",
    "        num_partitions=num_clients,\n",
    "        partition_by=\"label\",\n",
    "        alpha=alpha,\n",
    "        min_partition_size=30,\n",
    "    )\n",
    "    return FederatedDataset(\n",
    "        dataset=dsname,\n",
    "        partitioners={\"train\": partitioner},\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "\n",
    "fds = split_data(global_args.dsname, global_args.num_clients, global_args.alpha)\n",
    "\n",
    "def load_data(partition_id: int, batch_size: int = 256) -> DataLoader:\n",
    "    dataset = fds.load_partition(partition_id=partition_id)\n",
    "\n",
    "    def apply_train_transforms(batch):\n",
    "        \"\"\"Apply transforms to the partition from FederatedDataset.\"\"\"\n",
    "        batch[\"image\"] = [transform_train(img.convert('RGB')) for img in batch[\"image\"]]\n",
    "        return batch\n",
    "\n",
    "    dataset = dataset.with_transform(apply_train_transforms)\n",
    "    trainloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    return trainloader\n",
    "\n",
    "\n",
    "# Load the (global) test dataset\n",
    "def load_global_test_data() -> DataLoader:\n",
    "    testset = fds.load_split(\"valid\")\n",
    "\n",
    "    def apply_test_transforms(batch):\n",
    "        \"\"\"Apply transforms to the partition from FederatedDataset.\"\"\"\n",
    "        batch[\"image\"] = [transform_test(img.convert('RGB')) for img in batch[\"image\"]]\n",
    "        return batch\n",
    "\n",
    "    testset = testset.with_transform(apply_test_transforms)\n",
    "    testloader = DataLoader(\n",
    "        testset,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    return testloader\n",
    "\n",
    "\n",
    "# Train and test on a trainloader and testloader\n",
    "def train(model: nn.Module, trainloader: DataLoader, **kwargs):\n",
    "    \"\"\"Train the model on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    current_round = kwargs[\"ins\"].config[\"current_round\"]\n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=model.parameters(), lr=1e-3\n",
    "    )\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    for _ in range(5):\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            if i > 10:\n",
    "                pass\n",
    "            images, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def test(\n",
    "    model: nn.Module,\n",
    "    testloader: DataLoader,\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Validate the model on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    if len(testloader) == 0:\n",
    "        return np.inf, 0\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            if i > 10:\n",
    "                pass\n",
    "            images, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
    "            outputs = model(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    del (testloader, model)\n",
    "    torch.cuda.empty_cache()\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "def ndarrays_from_model(model: torch.nn.ModuleList) -> NDArrays:\n",
    "    \"\"\"Get model weights as a list of NumPy ndarrays.\"\"\"\n",
    "    return [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
    "\n",
    "\n",
    "def ndarrays_to_model(model: torch.nn.ModuleList, params: NDArrays):\n",
    "    \"\"\"Set model weights from a list of NumPy ndarrays.\"\"\"\n",
    "    params_dict = zip(model.state_dict().keys(), params)\n",
    "    state_dict = OrderedDict({k: torch.from_numpy(np.copy(v)) for k, v in params_dict})\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "# All training calls, to be sent to the server and clients\n",
    "\n",
    "\n",
    "from flwr.common import ndarrays_to_parameters\n",
    "\n",
    "\n",
    "def evaluate_fn(server_round, weights_aggregated, dict, **kwargs):\n",
    "    model = get_model()\n",
    "    ndarrays_to_model(model, weights_aggregated)\n",
    "    loss, accuracy = test(model, load_global_test_data())\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    return -loss, {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "def get_initial_parameters():\n",
    "    init_model = get_model()\n",
    "    initial_parameters = ndarrays_to_parameters(ndarrays_from_model(init_model))\n",
    "    del init_model\n",
    "    torch.cuda.empty_cache()\n",
    "    return initial_parameters\n",
    "\n",
    "\n",
    "def fit_config(server_round: int):\n",
    "    \"\"\"Generate training configuration for each round.\"\"\"\n",
    "    # Create the configuration dictionary\n",
    "    config = {\n",
    "        \"current_round\": server_round,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "\n",
    "client_resources: dict = {\n",
    "    \"num_cpus\": 1,\n",
    "    \"num_gpus\": 0.33333,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71eea8f-52ef-4c96-9cd7-540f4a35ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FlowerClient(Client):\n",
    "    def __init__(\n",
    "        self,\n",
    "        client_id: int,\n",
    "        training_calls: TrainingCalls,\n",
    "    ) -> None:\n",
    "        self.client_id = client_id\n",
    "        self.training_calls = training_calls\n",
    "        self.num_examples = len(self.training_calls.load_data(self.client_id))\n",
    "\n",
    "        self.round = 0\n",
    "        self.batchsize = 64\n",
    "\n",
    "    def fit(self, ins: FitIns) -> FitRes:\n",
    "\n",
    "        # Deserialize parameters to NumPy ndarray's\n",
    "        parameters_original = ins.parameters\n",
    "        ndarrays_original = parameters_to_ndarrays(parameters_original)\n",
    "        # Update local model, train, get updated parameters\n",
    "        model = self.training_calls.get_model()\n",
    "        self.training_calls.set_parameters(model, ndarrays_original)\n",
    "        trainloader = self.training_calls.load_data(self.client_id, self.batchsize)\n",
    "        self.training_calls.train(\n",
    "            model=model,\n",
    "            trainloader=trainloader,\n",
    "            ins=ins,\n",
    "        )\n",
    "        ndarrays_updated = self.training_calls.get_parameters(model)\n",
    "        del trainloader, model\n",
    "        torch.cuda.empty_cache()\n",
    "        # Serialize ndarray's into a Parameters object\n",
    "        parameters_updated = ndarrays_to_parameters(ndarrays_updated)\n",
    "        # Build and return response\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        logging.info(f\"Client {self.client_id} successfully trained.\")\n",
    "        return FitRes(\n",
    "            status=status,\n",
    "            parameters=parameters_updated,\n",
    "            num_examples=self.num_examples,\n",
    "            metrics={\"client_id\": self.client_id},\n",
    "        )\n",
    "\n",
    "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return EvaluateRes(\n",
    "            status=status,\n",
    "            loss=np.inf,\n",
    "            num_examples=self.num_examples,\n",
    "            metrics={\"accuracy\": 0},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf27d9-331c-45bc-9a71-0b9fba369256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapley_values\n",
    "import flwr_contributions\n",
    "\n",
    "\n",
    "def create_contribution_strategy(\n",
    "    parent_strategy: fl.server.strategy,\n",
    "    initial_parameters: Parameters,\n",
    "    trainingcalls: TrainingCalls,\n",
    "):\n",
    "\n",
    "    class FedContribution(parent_strategy):\n",
    "        def __init__(\n",
    "            self,\n",
    "            initial_parameters: Parameters = initial_parameters,\n",
    "            fraction_evaluate: float = 1.0,\n",
    "            min_fit_clients: int = 2,\n",
    "            min_evaluate_clients: int = 2,\n",
    "            min_available_clients: int = 2,\n",
    "            evaluate_fn: Optional[\n",
    "                Callable[\n",
    "                    [int, NDArrays, Dict[str, Scalar]],\n",
    "                    Optional[Tuple[float, Dict[str, Scalar]]],\n",
    "                ]\n",
    "            ] = None,\n",
    "            on_fit_config_fn: Callable = None,\n",
    "        ) -> None:\n",
    "            super().__init__()\n",
    "\n",
    "            self.evaluate_fn = evaluate_fn\n",
    "            self.results: List[Tuple[ClientProxy, FitRes]] = None\n",
    "            self.on_fit_config_fn = on_fit_config_fn\n",
    "\n",
    "            self.initial_parameters = initial_parameters\n",
    "            self.fraction_fit = globalargs.fraction_fit\n",
    "            self.fraction_evaluate = fraction_evaluate\n",
    "            self.min_fit_clients = min_fit_clients\n",
    "            self.min_evaluate_clients = min_evaluate_clients\n",
    "            self.min_available_clients = min_available_clients\n",
    "\n",
    "            self.trainingcalls = trainingcalls\n",
    "\n",
    "            self.contribution_dict = []\n",
    "\n",
    "            self.times = []\n",
    "\n",
    "        def aggregate_fit(\n",
    "            self,\n",
    "            server_round: int,\n",
    "            results: List[Tuple[ClientProxy, FitRes]],\n",
    "            failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "        ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "            \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
    "            if not results:\n",
    "                return None, {}\n",
    "\n",
    "            round_contributions = shapley_values.multi_round_reconstruction(server_round, \n",
    "                                                                            results, \n",
    "                                                                            failures, \n",
    "                                                                            self.evaluate_fn, \n",
    "                                                                            super().aggregate_fit,\n",
    "                                                                            global_args.sampler,\n",
    "                                                                            sample_ratio = .5\n",
    "                                                                           )\n",
    "            print(round_contributions)\n",
    "            self.contribution_dict.append(round_contributions)\n",
    "            return super().aggregate_fit(\n",
    "                server_round, results, failures\n",
    "            )\n",
    "\n",
    "        def evaluate(\n",
    "            self, server_round: int, parameters: Parameters\n",
    "        ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "            \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
    "            if self.evaluate_fn is None:\n",
    "                # No evaluation function provided\n",
    "                return None\n",
    "            parameters_ndarrays = parameters_to_ndarrays(parameters)\n",
    "            eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "\n",
    "            if eval_res is None:\n",
    "                return None\n",
    "            loss, metrics = eval_res\n",
    "            # At the last round, we save\n",
    "            if server_round == globalargs.max_rounds:\n",
    "                print(self.times)\n",
    "                print(self.contribution_dict)\n",
    "            return loss, metrics\n",
    "\n",
    "    return FedTimed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394ebb0-2167-4ca1-9e28-f4ff59588303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_calls: TrainingCalls = TrainingCalls()\n",
    "training_calls.get_model = get_model\n",
    "\n",
    "training_calls.train = train\n",
    "training_calls.test = test\n",
    "training_calls.get_parameters = ndarrays_from_model\n",
    "training_calls.set_parameters = ndarrays_to_model\n",
    "\n",
    "training_calls.load_data = load_data\n",
    "training_calls.load_global_test_data = load_global_test_data\n",
    "\n",
    "training_calls.get_initial_parameters = get_initial_parameters\n",
    "\n",
    "\n",
    "\n",
    "def client_fn(context: Context) -> FlowerClient:\n",
    "    partition_id: int = int(context.node_config[\"partition-id\"])\n",
    "    return FlowerClient(\n",
    "        client_id=partition_id,\n",
    "        training_calls=training_calls,\n",
    "    ).to_client()\n",
    "\n",
    "\n",
    "def fit_config(server_round: int):\n",
    "    \"\"\"Generate training configuration for each round.\"\"\"\n",
    "    # Create the configuration dictionary\n",
    "    config = {\n",
    "        \"current_round\": server_round,\n",
    "        \"max_round\": global_args.max_rounds,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "\n",
    "def start_simulation():\n",
    "    timed_strategy = create_timed_strategy(\n",
    "        FedAvg,\n",
    "        initial_parameters=training_calls.get_initial_parameters(),\n",
    "        trainingcalls=training_calls,\n",
    "    )\n",
    "    hist = fl.simulation.start_simulation(\n",
    "        client_fn=client_fn,\n",
    "        num_clients=global_args.num_clients,\n",
    "        config=fl.server.ServerConfig(num_rounds=global_args.max_rounds),\n",
    "        strategy=timed_strategy(\n",
    "            initial_parameters=training_calls.get_initial_parameters(),\n",
    "            evaluate_fn=evaluate_fn,\n",
    "            on_fit_config_fn=fit_config,\n",
    "        ),\n",
    "        client_resources=client_resources,\n",
    "    )\n",
    "\n",
    "start_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0200d7-54ff-4af7-b274-f3cb00cc5e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
